{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from scipy import linalg\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "\n",
    "    # Index of default block of inception to return,\n",
    "    # corresponds to output of final average pooling\n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "\n",
    "    # Maps feature dimensionality to their output blocks indices\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   # First max pooling features\n",
    "        192: 1,  # Second max pooling featurs\n",
    "        768: 2,  # Pre-aux classifier features\n",
    "        2048: 3  # Final average pooling features\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
    "                 resize_input=True,\n",
    "                 normalize_input=True,\n",
    "                 requires_grad=False):\n",
    "        \n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "\n",
    "        assert self.last_needed_block <= 3, \\\n",
    "            'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        inception = models.inception_v3(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "\n",
    "        # Block 0: input to maxpool1\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        # Block 1: maxpool1 to maxpool2\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "\n",
    "        # Block 2: maxpool2 to aux classifier\n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        # Block 3: aux classifier to final avgpool\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"Get Inception feature maps\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp : torch.autograd.Variable\n",
    "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
    "            range (0, 1)\n",
    "        Returns\n",
    "        -------\n",
    "        List of torch.autograd.Variable, corresponding to the selected output\n",
    "        block, sorted ascending by index\n",
    "        \"\"\"\n",
    "        outp = []\n",
    "        x = inp\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x,\n",
    "                              size=(299, 299),\n",
    "                              mode='bilinear',\n",
    "                              align_corners=False)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                outp.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return outp\n",
    "    \n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "model = InceptionV3([block_idx])\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
    "                    cuda=False):\n",
    "    model.eval()\n",
    "    act=np.empty((len(images), dims))\n",
    "    \n",
    "    if cuda:\n",
    "        batch=images.cuda()\n",
    "    else:\n",
    "        batch=images\n",
    "    pred = model(batch)[0]\n",
    "\n",
    "        # If model output is not scalar, apply global spatial average pooling.\n",
    "        # This happens if you choose a dimensionality not equal 2048.\n",
    "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fretchet(images_real,images_fake,model):\n",
    "     mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
    "     mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
    "    \n",
    "     \"\"\"get fretched distance\"\"\"\n",
    "     fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
    "     return fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'netG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a5ecaaf9a042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generator Parameters:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnetG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Discriminator Parameters:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'netG' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Generator Parameters:\",sum(p.numel() for p in netG.parameters() if p.requires_grad))\n",
    "print(\"Discriminator Parameters:\",sum(p.numel() for p in netD.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2a75dbe0b556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting Training Loop...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# For each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# For each batch in the dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, device=device).to(torch.float32)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(noise)\n",
    "                fake_display = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "    G_losses.append(errG.item())\n",
    "    D_losses.append(errD.item())     \n",
    "    fretchet_dist=calculate_fretchet(real_cpu,fake,model) \n",
    "    if ((epoch+1)%5==0):\n",
    "        \n",
    "        print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tFretchet_Distance: %.4f'\n",
    "                      % (epoch+1, num_epochs,\n",
    "                         errD.item(), errG.item(),fretchet_dist))\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.axis(\"off\")\n",
    "        pictures=vutils.make_grid(fake_display[torch.randint(len(fake_display), (10,))],nrow=5,padding=2, normalize=True)\n",
    "        plt.imshow(np.transpose(pictures,(1,2,0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1].cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
